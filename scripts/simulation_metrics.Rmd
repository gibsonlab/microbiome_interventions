---
title: "Gather Simulation Metrics"
output: 
  html_document:
    highlight: "kate"
date: "`r Sys.Date()`"
params:
  data: "~/Downloads/sim_input_001.rda"
  run_id: 1
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(glue)
library(tidyverse)
library(mbtransfer)
library(tfPaper)
set.seed(123)
```

```{r}
configurations <- expand.grid(
  method_hyper = c("mbtransfer-1", "mbtransfer-2", "mdsine"),
  normalization = c("none", "DESeq2", "relative_abundance", "mbImpute")
) |>
  separate(method_hyper, c("method", "hyper"), convert = TRUE) |>
  mutate(
    hyper = list(list(P = 2, Q = 2), list(P = 4, Q = 4))[hyper],
    output_path = glue("result_{row_number()}.rda")
  )

attach(as.list(configurations[params$run_id, ]))
hyper <- hyper[[1]]
```

This script doesn't presume to know which input datasets are to be considered.
It just runs on whatever data are available and computes metrics if possible.
The main parameters are related to cross validation, the method to use, the data
to use, and any ground truth needed in order to compute metrics.

```{r}
load(params$data)
hyper$taxonomy <- taxonomy

ts <- reads |>
  normalize(normalization, metadata) |>
  ts_from_dfs(interventions, metadata, subject_data) |>
  interpolate()
```

First, the forecasting metrics.

```{r}
tr_fun <- function(method, hyper = list()) {
  function(x) {
    train(x, method, hyper)
  }
}

result <- cross_validate(ts, tr_fun(method, hyper))
metrics <- result$metrics
# save the cross-validation metrics
```

```{r}
start <- Sys.time()
tr_fun(ts)
time_diff <- Sys.time() - start
save(metrics, time_diff, file = output_path)
```

Next, the hypothesis testing metrics.

```{r}
#load(params$mirror_counterfactuals)
#effects <- pd_splits(ts, w0, w1, 20, method = params$method)
#ms <- consistency_mirror_multiple(effects)
```

```{r}
#ms <- ms |>
#  mutate(truth = taxon %in% nonnull_taxa)
# ms_ <- ms |>
#   select(multisplit, m_, lag) %>% 
#   split(.$lag) %>%
#   map(~ split(., .$multisplit) %>% map(~ pull(., m_)))
# 
# lag <- 3
# if nonnull_taxa not present, then skip tteh evaluation
# R <- str_c("tax", which(multiple_data_splitting(ms_[[lag]])))
# S <- intersect(nonnull_taxa_,  R)
# V <- setdiff(R, nonnull_taxa_)

# save the false discovery rate metrics. We'll have a separate script for DESeq2
# / metagenomeSeq etc.
```

