---
title: "Gather Simulation Metrics"
output: 
  html_document:
    highlight: "kate"
date: "`r Sys.Date()`"
params:
  data_dir: "tf_sim/"
  run_id: 3
  qvalue: 0.2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r libraries}
library(glue)
library(fs)
library(DESeq2)
library(phyloseq)
library(tidyverse)
library(mbtransfer)
library(tfPaper)
set.seed(20230325)
```

```{r configurations}
configurations <- dir_ls(params$data_dir) |>
  path_abs() |>
  method_configurations() |>
  filter(map_lgl(hyper, ~ !is.null(.$P) > 0 && .$P == 2)) |>
  mutate(output_path = glue("inference-{str_pad(row_number(), 3, 'left', '0')}.rda"))

attach(as.list(configurations[params$run_id, ]))
```

This script doesn't presume to know which input datasets are to be considered.
It just runs on whatever data are available and computes metrics if possible.
The main parameters are related to cross validation, the method to use, the data
to use, and any ground truth needed in order to compute metrics.

```{r ts-object}
load(as.character(data_path))

interventions_df <- data.frame(interventions) |>
  rownames_to_column("sample")
metadata <- metadata |>
  left_join(interventions_df) |>
  rename(condition = P1)

ts <- reads |>
  normalize(normalization, metadata) |>
  ts_from_dfs(interventions, metadata, subject_data) |>
  interpolate()
```

### DESeq2

```{r run_deseq2}
samples <- metadata |>
  left_join(subject_data) |>
  column_to_rownames("sample") |>
  sample_data()

dds <- phyloseq(otu_table(reads, taxa_are_rows = FALSE), samples) |>
  phyloseq_to_deseq2(~ condition * V1) |>
  DESeq(sfType = "poscounts")
```

```{r, deseq_postprocessing}
R_deseq <- results(dds, name = "condition") |>
  data.frame() |>
  rownames_to_column("taxon") |>
  filter(padj < params$qvalue) |>
  mutate(taxon = as.integer(str_remove(taxon, "tax"))) |>
  pull(taxon)

lags <- unlist(hyper[[1]])
R_deseq <- replicate(max(lags), R_deseq, simplify = FALSE)
```

### Averaging baseline

This baseline approach compares each taxon's abundance immediately pre/post
intervention using a simple t-test. It doesn't differentiate between lagged
effects and is just aimed at detecting whether the intervention has any effect
at all.

```{r, averaging_baseline}
pre <- which(colData(dds)$time > -hyper[[1]]$Q, colData(dds)$time < 0)
post <- which(colData(dds)$time < hyper[[1]]$Q, colData(dds)$time >= 0)

p_values <- vector(length = nrow(dds))
for (j in seq_len(nrow(dds))) {
  p_values[j] <- t.test(assay(dds)[j, pre], assay(dds[j, post]))$p.value
}

adjp <- p.adjust(p_values, method = "BH")
R_avg <- replicate(max(lags), which(adjp < params$qvalue), simplify = FALSE)
```

### Mirror-based testing

```{r multisplit_mirrors}
tr_fun <- function(x) {
  mbtransfer(x, P = hyper[[1]]$P, Q = hyper[[1]]$Q)
}

ws <- steps(c("P1" = TRUE), lengths = max(lags), L = max(lags))
staxa <- select_taxa(ts, ws[[1]], ws[[2]], tr_fun, n_splits = 25, qvalue = params$qvalue)
R_mirror <- map(staxa$taxa, ~ as.integer(str_remove(., "tax")))
```

### Combining results

```{r combined_results}
testing_results <- list()
testing_results$DESeq2 <- lagged_testing_metrics(R_deseq, nonnull_taxa)
testing_results$mirror <- lagged_testing_metrics(R_mirror, nonnull_taxa)
testing_results$avg <- lagged_testing_metrics(R_avg, nonnull_taxa)
testing_results <- bind_rows(testing_results, .id = "method")
```

```{r save_results}
save(testing_results, file = output_path)
```

```{r session}
sessionInfo()
```