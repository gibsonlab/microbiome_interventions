---
title: "Gather Simulation Metrics"
output: 
  html_document:
    highlight: "kate"
date: "`r Sys.Date()`"
params:
  data_dir: "tf_sim/"
  run_id: 1
  qvalue: 0.2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r libraries}
library(glue)
library(fs)
library(DESeq2)
library(phyloseq)
library(tidyverse)
library(mbtransfer)
library(tfPaper)
set.seed(20230325)
```

```{r configurations}
configurations <- dir_ls(params$data_dir) |>
  path_abs() |>
  method_configurations() |>
  filter(map_lgl(hyper, ~ !is.null(.$P) > 0 && .$P == 2)) |>
  mutate(output_path = glue("inference-{str_pad(row_number(), 3, 'left', '0')}.rda"))

attach(as.list(configurations[params$run_id, ]))
```

This script doesn't presume to know which input datasets are to be considered.
It just runs on whatever data are available and computes metrics if possible.
The main parameters are related to cross validation, the method to use, the data
to use, and any ground truth needed in order to compute metrics.

```{r ts-object}
load(as.character(data_path))

interventions_df <- data.frame(interventions) |>
  rownames_to_column("sample")
metadata <- metadata |>
  left_join(interventions_df) |>
  rename(condition = P1)

ts <- reads |>
  normalize(normalization, metadata) |>
  ts_from_dfs(interventions, metadata, subject_data) |>
  interpolate()
```

### DESeq2

```{r run_deseq2}
samples <- metadata |>
  left_join(subject_data) |>
  column_to_rownames("sample") |>
  sample_data()

dds <- phyloseq(otu_table(reads, taxa_are_rows = FALSE), samples) |>
  phyloseq_to_deseq2(~ condition * V1) |>
  DESeq(sfType = "poscounts")
```

```{r, deseq_postprocessing}
R_deseq <- results(dds, name = "condition") |>
    data.frame() |>
    rownames_to_column("taxon") |>
    filter(padj < params$qvalue) |>
    mutate(taxon = as.integer(str_remove(taxon, "tax"))) |>
    pull(taxon)

lags <- unlist(hyper[[1]])
R_deseq <- replicate(max(lags), R_deseq, simplify = FALSE)
```

### Mirror-based testing

```{r multisplit_mirrors}
ws <- steps(c("P1" = TRUE), L = max(lags))
tr_fun <- function(x) {
  mbtransfer(x, P = hyper[[1]]$P, Q = hyper[[1]]$Q)
}

effects <- pd_splits(ts, ws[[1]], ws[[2]], 3, tr_fun, n_sample = 10)
ms <- consistency_mirror_multisplit(effects)
```

```{r false_discovery_estimates}
R_mirror <- ms |>
  select(multisplit, m, lag) %>%
  split(.$lag) %>%
  map(~ split(., .$multisplit) %>% map(~ pull(., m))) |>
  map(~ which(multiple_data_splitting(., q = params$qvalue)))
```

### Combining results

```{r combined_results}
testing_results <- list()
testing_results$DESeq2 <- lagged_testing_metrics(R_deseq, nonnull_taxa)
testing_results$mirror <- lagged_testing_metrics(R_mirror, nonnull_taxa)
testing_results <- bind_rows(testing_results, .id = "method")
```

```{r save_results}
save(testing_results, fit, ms, file = output_path)
```

```{r session}
sessionInfo()
```
