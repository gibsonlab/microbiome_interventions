---
title: "Gather Simulation Metrics"
output: 
  html_document:
    highlight: "kate"
date: "`r Sys.Date()`"
params:
  data_dir: "tf_sim/"
  run_id: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r libraries}
library(fido2)
library(fs)
library(glue)
library(mbtransfer)
library(mdsine)
library(tfPaper)
library(tidyverse)
set.seed(20230412)
```

We first generate data and methods configuration for the current simulation run.
The approach is to generate all possible configurations and then subset to the
current run of interest.

```{r configurations}
configurations <- dir_ls(params$data_dir) |>
  path_abs() |>
  method_configurations() |>
  mutate(data_path_base = basename(as.character(data_path)))

data_config <- data_parameters() |>
  mutate(data_path_base = basename(output_path)) |>
  select(-output_path)

configurations <- configurations |>
  left_join(data_config) |>
  filter(!(method == "mdsine" & n_taxa > 200))


attach(as.list(configurations[params$run_id, ]))

if (method == "mbtransfer") {
  predict <- mbtransfer::predict
} else if (method == "mdsine") {
  predict <- mdsine::predict
} else if (method == "fido") {
  predict <- fido2::predict
}
```

Next, we generate the `ts` object associated with the current simulation data.
The data are expected to be stored in the `data_path` and to have been generated
using the `simulation_data.Rmd` script.

```{r ts-object}
load(as.character(data_path))
hyper <- c(hyper[[1]], list(taxonomy = taxonomy))

interventions_df <- data.frame(interventions) |>
  rownames_to_column("sample")
metadata <- metadata |>
  left_join(interventions_df) |>
  rename(condition = P1)
reads[reads > .Machine$integer.max] <- .Machine$integer.max - 1

ts <- reads |>
  normalize(normalization, metadata) |>
  ts_from_dfs(interventions, metadata, subject_data) |>
  interpolate()
```

We compute forecasting errors using cross validation. Our implementation uses
functional programming. It expects, as input, a training funciton that outputs
an object with a `predict` method. This is used to make predictions on the
holdout fold. We also compute the time it took for cross-validation and report
the per-fold average training time.

```{r cross_validation}
tr_fun <- function(method, hyper = list()) {
  function(x) {
    if (method == "mdsine") {
      mdsine(ts, hyper$taxonomy)
    } else if (method == "mbtransfer") {
      mbtransfer(ts, P = hyper$P, Q = hyper$Q)
    } else if (method == "fido") {
      fido(ts, sigma = hyper$sigma, rho = hyper$rho)
    }
  }
}

start <- Sys.time()
result <- cross_validate(ts, tr_fun(method, hyper), K = 4)
time_diff <- (Sys.time() - start) / 4
metrics <- result$metrics
```

```{r save_results}
save(metrics, time_diff, file = output_path)
sessionInfo()
```
