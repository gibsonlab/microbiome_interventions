---
title: "simulation"
output: pagedown::book_crc
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
library(phyloseq)
library(DESeq2)
library(microTF)
theme_set(theme_bw())
set.seed(20230317)
```

This generates the coefficient matrices for dynamics, perturbations, and
interactions.

```{r}
n_subject <- 100
n_time <- 30
n_lag <- 3
n_taxa <- 10
#n_taxa <- 100
n_perturb <- 1
n_latent <- 2
n_covariates <- 3
prop_nonnull <- 0.2

A <- low_rank_step(n_taxa, n_latent, n_taxa, n_lag) |>
 sparsify(1) #|>
 #normalize(0.8)
B <- low_rank_step(n_taxa, n_latent, n_perturb, n_lag, lower = -1.5, upper = 1.5)

nonnull_taxa <- sample(n_taxa, prop_nonnull * n_taxa)
for (i in seq_along(B)) {
  B[[i]][-nonnull_taxa, ] <- 0
}

C <- low_rank_step_(n_taxa, n_latent, n_perturb, n_lag)
for (i in seq_along(C)) {
  C[[i]] <- C[[i]] |>
    sparsify() |>
    normalize(0.2)
}
```

Now we can simulate one example series.

For negative binomial simulation, remember that if the variance is $\mu$, the
variance is $\mu + \frac{1}{\text{size}}\mu^2$, where $\text{size}$ is the
number of successes before we stop.

```{r}
step_generator <- step_t(linear_sum(A), linear_sum(B), interaction_sum(C))
theta0 <- matrix(2, n_taxa, n_lag + 1)

w <- replicate(n_subject, matrix(0, n_perturb, n_time), simplify = FALSE)
for (i in seq_along(w)) {
  for (j in seq_len(n_perturb)) {
    start_ix <- sample((n_time / 3) : (n_time - n_lag), 1)
    end_ix <- start_ix + sample((n_lag / 2) : (2 * n_lag), 1)
    w[[i]][j, start_ix:min(n_time, end_ix)] <- 1
  }
}

z <- matnorm(n_subject, n_covariates)
sizes <- runif(n_taxa, .1, 10)
baselines <- rgamma(n_taxa, 40, 4)

x <- list()
for (i in seq_len(n_subject)) {
  x[[i]] <- generate_sample(theta0, w[[i]], z[i, ], step_generator, nbinom_sampler(sizes, baselines))
  rownames(x[[i]]) <- str_c("tax", seq_len(n_taxa))
}
```

Next, we can plot the series.

```{r}
x_df <- map_dfr(x, ~ as_tibble(.) |> rownames_to_column("taxon"), .id = "subject") |>
  pivot_longer(starts_with("V"), names_to = "time") |>
  mutate(
    time = as.integer(str_remove(time, "V")),
    taxon = str_c("tax", taxon)
  ) |>
  filter(time  > n_lag)

B_df <- map_dfr(
  B, ~ as_tibble(.) |> 
    mutate(taxon = str_c("tax", row_number())),
  .id = "lag") |>
  pivot_wider(names_from = "lag", values_from = "V1")

x_df <- x_df |>
  left_join(B_df) %>%
  mutate(effect = rowSums(.[, -c(1:4)]))
  
start_ix <- min(which(w[[2]][1, ] == 1))
end_ix <- max(which(w[[2]][1, ] == 1))

x_df |>
  filter(effect != 0, subject == 2) |>
  ggplot(aes(time, value)) +
  geom_rect(xmin = start_ix, xmax = end_ix, ymin = 0, ymax = max(x_df$value), fill = "#d3d3d3") +
  geom_line(aes(col = effect, group = subject)) +
  facet_wrap(~ reorder(taxon, effect), scale = "free_y") +
  scale_y_sqrt() +
  scale_color_gradient2(mid = "#d3d3d3")
```


```{r}
w_df <- map_dfr(w, ~ as_tibble(.), .id = "subject") |>
  pivot_longer(-subject, names_to = "time", values_to = "w") |>
  mutate(
    time = as.integer(str_remove(time, "V")),
    value = w,
    sample = str_c("sam", row_number())
  )

w_df_ <- w_df |>
  filter(w != 0, time > n_lag)

x_df |>
  filter(taxon == str_c("tax", tail(nonnull_taxa, 1))) |>
  ggplot(aes(time, reorder(subject, value))) +
  geom_tile(aes(fill = log(1 + value))) +
  geom_point(data = w_df_, shape = 1) +
  scale_fill_distiller(direction = 1)
```

### DESeq2

If we were using DESeq2, how would we test?

```{r}
reads <- map_dfc(x, ~ .[, -seq_len(n_lag)]) |>
  as.matrix()
rownames(reads) <- str_c("tax", seq_len(n_taxa))
colnames(reads) <- w_df |>
  filter(time > n_lag) |>
  pull(sample)

ps <- phyloseq(
  otu_table(reads, taxa_are_rows = TRUE),
  sample_data(select(w_df, -value) |> column_to_rownames("sample"))
)

dds  <- phyloseq_to_deseq2(ps, ~ w)
dds <- DESeq(dds)
```

```{r}
significant <- results(dds) |>
  data.frame() |>
  rownames_to_column("taxon") |>
  filter(padj < 0.2)

significant |>
  arrange(padj)
```

These are the taxa that DESeq2 thinks are significant. We've ordered by
estimated log fold change and colored by the true perturbation effect.

```{r}
x_df |>
  right_join(select(significant, taxon, log2FoldChange, padj) |> filter(padj < 1e-6)) |>
  filter(subject == 1) |>
  ggplot() +
  geom_rect(xmin = start_ix, xmax = end_ix, ymin = 0, ymax = max(x_df$value), fill = "#d3d3d3") +
  geom_line(aes(time, value, col = effect)) +
  facet_wrap(~ reorder(taxon, log2FoldChange)) +
  scale_y_log10() +
  scale_color_gradient2(mid = "#d3d3d3")
```

```{r}
nonnull_taxa_ <- str_c("tax", nonnull_taxa)

R <- significant$taxon
S <- intersect(nonnull_taxa_,  significant$taxon)
V <- setdiff(significant$taxon, nonnull_taxa_)
```

At a $q$-level of 0.2, the FDP is `r length(V) / length(R)`. The power is 
`r length(S) / nrow(significant)`. There are a lot of false positives.

### Mirror-Based Testing

```{r}
subject_data <- z |>
  as_tibble() |>
  mutate(subject = row_number())

metadata <- expand.grid(
    time = seq_len(n_time),
    subject = seq_len(n_subject)
  ) |>
  mutate(sample = str_c("sam", row_number())) |>
  filter(time > n_lag)

interventions <- w_df |>
  filter(time > n_lag) |>
  pull(w, sample) |>
  as.matrix()

reads <- log(1 + reads)
ts <- ts_from_dfs(t(reads), interventions, metadata, subject_data)
```

Now, how can we get the y1 and y0 for each person across the two splits? Note
that we don't have to apply the model to the test split (unlike everything else
we've been taught) -- it's going to be enough to ensure sign consistency across
splits.


```{r}
pdp_generator <- function(ts, lags, qs = c(0.25, 0.5, 0.75), ...) {
  x <- patchify_df(ts, lags[1], lags[2])$x
  
  function(partial_x, fit) {
    pnames <- intersect(colnames(partial_x), colnames(x))
    
    y_hat <- list()
    nx <- nrow(partial_x)
    for (j in seq_along(fit)) {
      y_hat[[j]] <- matrix(nrow = nx, ncol = length(qs) + 2)
      colnames(y_hat[[j]]) <- c("index", str_c("q", qs), "mean")
      x_ <- x
 
      for (i in seq_len(nx)) {
        x_[, pnames] <- unlist(partial_x[i, ])
        y_hat_ji <- predict(fit[[j]], x_)
        y_hat[[j]][i, ] <- c(
          i,
          quantile(y_hat_ji, qs),
          mean(y_hat_ji)
        )
      }
    }
    
    y_hat
  }
}

new_x <- tibble(
  intervention1_lag0 = c(1, 0), 
  intervention1_lag1 = c(0, 0),
  intervention1_lag2 = c(0, 0),
  intervention1_lag3 = c(0, 0),
  intervention1_lag4 = c(0, 0)
)

pdps <- list()
pdp_fun <- pdp_generator(ts, c(n_lag, n_lag))

k <- 1
for (s in seq_len(100)) {
  print(s)
  split_ix <- sample(seq_along(ts), 0.5 * length(ts))
  hyper <- list(P = n_lag, Q = n_lag)
  fits <- list(
    train(ts[split_ix], method = "gbm", hyper = hyper),
    train(ts[-split_ix], method = "gbm", hyper = hyper)
  )
  
  for (split in seq_len(2)) {
    pdps[[k]] <- pdp_fun(new_x, fits[[split]]@parameters) %>%
      map_dfr(as_tibble, .id = "taxon") %>%
      mutate(
        taxon = str_c("tax", taxon),
        split = split,
        multisplit = s
      )
    k <- k + 1
  }
}

pdps0 <- pdps
```


```{r}
bind_rows(pdps0) %>%
  select(multisplit, split, taxon, index, mean) %>%
  pivot_wider(names_from = index, values_from = mean) %>%
  mutate(difference = `1` - `2`) %>%
  ggplot() +
  geom_vline(xintercept = 0) +
  geom_point(aes(difference, reorder(taxon, difference), col = as.factor(split)), position = position_jitter(h = 0.1))
```

```{r}
bind_rows(pdps0) %>%
  select(multisplit, split, taxon, index, mean) %>%
  pivot_wider(names_from = index, values_from = mean) %>%
  mutate(difference = `1` - `2`) %>%
  select(multisplit, split, taxon, difference) %>%
  pivot_wider(names_from = split, values_from = difference) %>%
  mutate(sign = sign(`1` * `2`), magnitude = 0.5 * (`1` + `2`)) %>%
  group_by(taxon) %>%
  summarise(m_sign = mean(sign), m_magnitude = mean(magnitude)) %>%
  arrange(-m_sign, -m_magnitude)
```

```{r}
splits <- split_estimates(ts, 2)
```

```{r}
m <- temporal_mirror(splits[[1]])
  
m_df <- m |>
  as_tibble() |>
  mutate(truth = row_number() %in% nonnull_taxa) |>
  dplyr::rename(m = value) |>
  arrange(m) |>
  mutate(ix = row_number())

ggplot(m_df) +
  geom_histogram(aes(m, fill = truth), position = "identity", alpha = 0.5, bins = 40) + 
  facet_grid(. ~ truth, scale = "free")
```

```{r}
ms <- multiple_split_mirror(splits)
S_hat <- which(multiple_data_splitting(ms, 1))
S <- nonnull_taxa

length(setdiff(S_hat, S)) / length(S_hat)
length(intersect(S_hat, S)) / length(S)
```

```{r}
ms_df <- bind_rows(ms, .id = "split") %>%
  pivot_longer(-split, names_to = "taxon") %>%
  mutate(truth = taxon %in% nonnull_taxa_)

ggplot(ms_df) +
  geom_histogram(aes(value, fill = truth)) +
  facet_wrap(~ truth, scales = "free_y")
```


```{r, fig.height = 10, fig.width = 4}
ggplot(ms_df) +
  geom_point(aes(value, reorder(taxon, value))) +
  facet_grid(truth ~ ., space = "free_y", scales = "free_y")
```

```{r}
counter_df <- list()
i <- 1
for (k in seq_along(splits)) {
  for (s in seq_along(splits[[k]])) {
    for (subject in seq_along(splits[[k]][[s]])) {
      for (counter in c("y1", "y0")) {
        cur <- as_tibble(splits[[k]][[s]][[subject]][[counter]]) %>%
          mutate(taxon = str_c("tax", row_number())) %>%
          pivot_longer(-taxon, names_to = "sample") %>%
          group_by(taxon) %>%
          mutate(
            time = row_number(),
            subject = subject,
            counter = counter,
            split = s,
            multisplit = k
          )
        counter_df[[i]] <- cur
        i <- i + 1
      }
    }
  }
}

counter_df <- bind_rows(counter_df)

counter_df2 <- counter_df %>%
  pivot_wider(names_from = "counter", values_from = "value") %>%
  group_by(taxon, subject, split, multisplit) %>%
  mutate(int_diff = mean(y1 - y0))
```

```{r}
counter_df %>%
  filter(taxon %in% c("tax1", "tax3", "tax74", "tax95"), multisplit < 5, subject < 4) %>%
  ggplot() +
  geom_line(aes(time, value, col = counter, group = interaction(subject, counter))) +
  facet_grid(multisplit + split ~ taxon)
```


```{r}
counter_df2 %>%
  filter(taxon %in% c("tax1", "tax3", "tax74", "tax95"), multisplit < 5) %>%
  ggplot() +
  geom_ribbon(aes(time, ymin = y0, ymax = y1, fill = int_diff, group = interaction(subject, counter, split)), alpha = 0.8) +
  facet_grid(multisplit  + split ~ taxon) +
  scale_fill_gradient2(mid = "#d3d3d3")
```

```{r}
counter_df2 %>%
  filter(y1 != y0, taxon %in% c("tax1", "tax2", "tax3")) %>%
  ggplot() +
  geom_histogram(aes(y1 - y0)) +
  geom_vline(xintercept = 0, col = "red") +
  facet_grid(multisplit + split ~ taxon)
```

```{r}
map_dfr(ms, fdp_hat, .id = "split") |>
  ggplot() +
  geom_step(aes(t, fdp, group = split))
```

